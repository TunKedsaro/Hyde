{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23da4311",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Docstring for sandbox.2601281516-04.ipynb\n",
    "This .ipynb create for run all pipeline-1 in Jupyterlab that run on Container\n",
    "before separate code\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b23db83f-2fe8-4ed8-9fcb-7fcedc4e51d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timezone\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cae1806-4aee-45e9-9e58-74e09a7842ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.utils.logging import get_logger\n",
    "from functions.utils.config  import PROJECT_ROOT, load_config\n",
    "from functions.utils.llm_client import build_llm_client_from_yaml\n",
    "from functions.utils.text_embeddings import GoogleEmbeddingModel\n",
    "from functions.core.context_builder import build_user_context\n",
    "from functions.core.history import build_history_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2b44bf-57ee-442e-83e0-78be3510f3ce",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af31a596-d771-4970-ad1e-1765b4df13df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(path: str) -> None:\n",
    "    \"\"\"Create directory if it does not exist (idempotent).\"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "def _read_hyde_config(cfg: Dict[str, Any]) -> Tuple[int, int, int, bool, str]:\n",
    "    \"\"\"\n",
    "    Read HyDE-related configuration with safe defaults.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    history_threshold:\n",
    "        Event count threshold for prompt selection\n",
    "    recent_k:\n",
    "        Max number of recent feeds used in HistorySummary\n",
    "    feed_text_max_chars:\n",
    "        Per-feed text truncation limit\n",
    "    include_recent_feeds:\n",
    "        Whether HistorySummary may include feed snippets\n",
    "    query_embedding_model_name:\n",
    "        Embedding model for HyDE queries\n",
    "    \"\"\"\n",
    "    hyde_cfg = cfg.get(\"hyde\", {}) if isinstance(cfg, dict) else {}\n",
    "\n",
    "    history_threshold = int(hyde_cfg.get(\"history_threshold\", 5))\n",
    "    recent_k = int(hyde_cfg.get(\"recent_k\", 5))\n",
    "    feed_text_max_chars = int(hyde_cfg.get(\"feed_text_max_chars\", 240))\n",
    "    include_recent_feeds = bool(hyde_cfg.get(\"include_recent_feeds\", True))\n",
    "\n",
    "    # Default to same embedding family as feed embeddings\n",
    "    query_embedding_model_name = str(\n",
    "        hyde_cfg.get(\"query_embedding_model_name\")\n",
    "        or cfg.get(\"embeddings\", {}).get(\"model_name\", \"\")\n",
    "        or \"gemini-embedding-001\"\n",
    "    )\n",
    "\n",
    "    # Hard safety guards\n",
    "    history_threshold = max(1, history_threshold)\n",
    "    recent_k = max(0, min(recent_k, 10))\n",
    "    feed_text_max_chars = max(0, min(feed_text_max_chars, 2000))\n",
    "\n",
    "    return (\n",
    "        history_threshold,\n",
    "        recent_k,\n",
    "        feed_text_max_chars,\n",
    "        include_recent_feeds,\n",
    "        query_embedding_model_name,\n",
    "    )\n",
    "def read_jsonl(path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Deterministic JSONL reader.\n",
    "\n",
    "    Order is preserved, which is critical for any downstream alignment.\n",
    "    \"\"\"\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line_no, line in enumerate(f, start=1):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                rows.append(json.loads(line))\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Invalid JSONL at line {line_no}: {e}\") from e\n",
    "    return rows\n",
    "\n",
    "def load_prompts() -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Load HyDE prompt templates from parameters/prompts.yaml.\n",
    "\n",
    "    Expected structure:\n",
    "      hyde_prompts:\n",
    "        hyde_a: \"...\"\n",
    "        hyde_b: \"...\"\n",
    "        hyde_c: \"...\"\n",
    "    \"\"\"\n",
    "    import yaml\n",
    "\n",
    "    prompts_path = PROJECT_ROOT / \"parameters\" / \"prompts.yaml\"\n",
    "    with prompts_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data = yaml.safe_load(f) or {}\n",
    "\n",
    "    return data.get(\"hyde_prompts\", {}) or {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031ca829-4bd6-4c02-9a4c-db6d8c12eb16",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97aa19c5-9141-4247-8861-09ef9a6df965",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger(\"pipeline_1_user_hyde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87d2308-1a94-40bc-809c-e6c03b704db0",
   "metadata": {},
   "source": [
    "### Load resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16730fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config()\n",
    "# cfg                                                  # warning APIkey leak\n",
    "students_path = cfg[\"data\"][\"students_path\"]           # 'data/students.csv'\n",
    "interactions_path = cfg[\"data\"][\"interactions_path\"]   # 'data/interactions.csv'\n",
    "feeds_path = cfg[\"data\"][\"feeds_path\"]                 # 'data/feeds.jsonl'\n",
    "out_dir = cfg[\"artifacts\"][\"user_query_bundles_dir\"]\n",
    "\n",
    "students     = pd.read_csv(students_path)\n",
    "interactions = pd.read_csv(interactions_path)\n",
    "if \"student_id\" not in students.columns:\n",
    "    raise ValueError(f\"students.csv missing 'student_id': {students_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dc652b-efa6-41ac-a5bd-217c9e6e6731",
   "metadata": {},
   "source": [
    "### Create output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "364fbc9e-115c-4edd-b7f7-b9dd2cbce430",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_dir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41d531f1-5de8-4604-8dca-4cd4a2889116",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_inter_cols = {\"user_id\", \"feed_id\", \"event_type\"}\n",
    "missing_cols = required_inter_cols - set(interactions.columns)\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"interactions.csv missing columns {sorted(missing_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2f4d6d-ad1f-4bdc-90c1-022ef9efcb83",
   "metadata": {},
   "source": [
    "### Read HyDE-related configuratioin once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cb641e4-2675-4fc0-8586-81f9b21b52a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(history_threshold,recent_k,feed_text_max_chars,include_recent_feeds,query_embedding_model_name) = _read_hyde_config(cfg)\n",
    "expected_dim = int(cfg.get(\"embeddings\", {}).get(\"dim\", 0) or 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b3d7889-a0d6-4bc1-bfc3-99a31e2b4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "feeds_lookup: Dict[str, Dict[str, Any]] = {}\n",
    "if os.path.exists(feeds_path):\n",
    "    feeds = read_jsonl(feeds_path)\n",
    "    feeds_lookup = {\n",
    "        str(f.get(\"feed_id\")): f\n",
    "        for f in feeds\n",
    "        if isinstance(f, dict) and f.get(\"feed_id\") is not None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c842520-c8d7-425b-a6de-39559129c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = load_prompts()\n",
    "if not prompts:\n",
    "    raise ValueError(\"hyde_prompts missing from parameters/prompts.yaml\")\n",
    "client = build_llm_client_from_yaml(\n",
    "    parameters_path=str(PROJECT_ROOT / \"parameters\" / \"parameters.yaml\"),\n",
    "    credentials_path=str(PROJECT_ROOT / \"parameters\" / \"credentials.yaml\"),\n",
    ")\n",
    "query_embedder = GoogleEmbeddingModel(\n",
    "    model_name=query_embedding_model_name,\n",
    "    credentials_path=str(PROJECT_ROOT / \"parameters\" / \"credentials.yaml\"),\n",
    ")\n",
    "now_iso = datetime.now(timezone.utc).replace(microsecond=0).isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5671e5cc-a4a6-4c10-881b-a79f9e5edbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94413314-21b1-4bdc-9110-e96accdeef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Prompt selection and rendering\n",
    "# =============================================================================\n",
    "def choose_hyde_prompt_key(num_events: int, history_threshold: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Select HyDE prompt variant based on interaction volume.\n",
    "\n",
    "    Rules\n",
    "    -----\n",
    "    - num_events >= history_threshold → history-heavy (hyde_b)\n",
    "    - num_events <= 1               → onboarding / sparse (hyde_c)\n",
    "    - otherwise                     → mixed (hyde_a)\n",
    "    \"\"\"\n",
    "    if num_events >= history_threshold:\n",
    "        return \"hyde_b\"\n",
    "    if num_events <= 1:\n",
    "        return \"hyde_c\"\n",
    "    return \"hyde_a\"\n",
    "\n",
    "\n",
    "def render_prompt(\n",
    "    template: str,\n",
    "    preferred_language: str,\n",
    "    user_context_text: str,\n",
    "    history_summary_text: Optional[str],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Render a prompt template using strict placeholder substitution.\n",
    "\n",
    "    Supported placeholders:\n",
    "    - {{preferred_language}}\n",
    "    - {{UserContextText}}\n",
    "    - {{HistorySummaryText}}\n",
    "\n",
    "    No templating engine is used on purpose to keep behavior explicit.\n",
    "    \"\"\"\n",
    "    s = template.replace(\"{{preferred_language}}\", preferred_language or \"th\")\n",
    "    s = s.replace(\"{{UserContextText}}\", user_context_text or \"\")\n",
    "    s = s.replace(\"{{HistorySummaryText}}\", history_summary_text or \"\")\n",
    "    return s\n",
    "\n",
    "# =============================================================================\n",
    "# HyDE output handling\n",
    "# =============================================================================\n",
    "def _extract_hyde_query_texts(hyde_json: Dict[str, Any]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract query_text values from HyDE JSON output.\n",
    "\n",
    "    Expected structure:\n",
    "      {\n",
    "        \"hyde_queries\": [\n",
    "          {\"query_id\": \"...\", \"query_text\": \"...\", ...},\n",
    "          ...\n",
    "        ]\n",
    "      }\n",
    "\n",
    "    Order is preserved and MUST match embedding row order.\n",
    "    \"\"\"\n",
    "    if not isinstance(hyde_json, dict):\n",
    "        raise ValueError(\"hyde_output must be a dict\")\n",
    "\n",
    "    items = hyde_json.get(\"hyde_queries\") or []\n",
    "    if not isinstance(items, list):\n",
    "        raise ValueError(\"hyde_output.hyde_queries must be a list\")\n",
    "\n",
    "    out: List[str] = []\n",
    "    for i, it in enumerate(items):\n",
    "        if not isinstance(it, dict):\n",
    "            raise ValueError(f\"hyde_output.hyde_queries[{i}] must be an object\")\n",
    "        out.append(str(it.get(\"query_text\") or \"\").strip())\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def _l2_normalize_rows(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Row-wise L2 normalization.\n",
    "\n",
    "    Zero rows are left as zero to avoid NaNs.\n",
    "    \"\"\"\n",
    "    if x.ndim != 2:\n",
    "        raise ValueError(\"Expected 2D array for row normalization\")\n",
    "\n",
    "    norms = np.linalg.norm(x, axis=1, keepdims=True)\n",
    "    norms[norms == 0.0] = 1.0\n",
    "    return (x / norms).astype(np.float32)\n",
    "\n",
    "\n",
    "def _atomic_save_npy(path: str, arr: np.ndarray) -> None:\n",
    "    \"\"\"\n",
    "    Best-effort atomic .npy write.\n",
    "\n",
    "    Writes to a temp file and renames to avoid partial reads.\n",
    "    \"\"\"\n",
    "    tmp = path + \".tmp.npy\"\n",
    "    np.save(tmp, arr)\n",
    "    os.replace(tmp, path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c8b8a-963f-4c76-af34-6a075eba5071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "promt_key -> hyde_b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29T02:38:30Z | INFO | functions.utils.llm_client | LLM call done | attempt=1 | latency=10.194s | in_tokens=890 | out_tokens=326 | model=gemini-2.5-flash | status=ok\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyde_query_texts->['แนวทางสร้างพอร์ต Data Analyst ด้วยโปรเจกต์ Python SQL', 'โจทย์ SQL Python สำหรับสัมภาษณ์ Data Analyst', 'โปรเจกต์วิเคราะห์ข้อมูล Python SQL สร้างพอร์ตฝึกงาน', 'เทคนิคการนำเสนอข้อมูลและสร้าง Dashboard ที่น่าสนใจ', 'คำแนะนำการเตรียมตัวสัมภาษณ์พฤติกรรม Data Analyst']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29T02:38:32Z | INFO | pipeline_1_user_hyde | wrote HyDE bundle student_id=stu_p001 events=9 prompt=hyde_b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb -> \n",
      "[[ 0.02000314 -0.0047342   0.01089853 ...  0.02991145  0.00380438\n",
      "   0.01089785]\n",
      " [-0.00057935 -0.03994162  0.00823921 ...  0.0290058   0.02110395\n",
      "   0.00760941]\n",
      " [ 0.01468005  0.00674358  0.02450645 ...  0.02964389  0.00659125\n",
      "   0.01269005]\n",
      " [-0.00210628  0.02196425  0.03479029 ...  0.04842292  0.00049197\n",
      "  -0.0097467 ]\n",
      " [ 0.00447448 -0.03216313  0.0003328  ...  0.0164042   0.03319886\n",
      "   0.00346774]]\n",
      "emb_path ->\n",
      "artifacts/user_query_bundles/stu_p001_hyde_q_emb.npy\n",
      "bundle->\n",
      "{'bundle_version': 'v2_hyde_embedded_queries', 'student_id': 'stu_p001', 'generated_at': '2026-01-29T02:38:20+00:00', 'prompt_key': 'hyde_b', 'preferred_language': 'th', 'num_events': 9, 'user_context_json': {'student_id': 'stu_p001', 'preferred_language': 'th', 'current_status': 'student3yr', 'education': {'level': 'bachelor', 'major': 'วิทยาการคอมพิวเตอร์'}, 'target_roles': [{'role_id': 'data_analyst', 'role_name': 'Data Analyst', 'priority': 1}], 'skills': [{'skill_id': 'python', 'skill_name': 'Python', 'proficiency': 'L2'}, {'skill_id': 'sql', 'skill_name': 'SQL', 'proficiency': 'L2'}], 'interests': ['ทำพอร์ต', 'ฝึกสัมภาษณ์'], 'onboard_grp': 'Job_Hunter', 'onboard_grp_description': 'เตรียมฝึกงานสายข้อมูล'}, 'user_context_text': 'นักศึกษา: วิทยาการคอมพิวเตอร์ (student3yr)\\nเป้าหมายอาชีพ: Data Analyst\\nทักษะ: Python:L2;SQL:L2\\nความสนใจ: ทำพอร์ต, ฝึกสัมภาษณ์\\nกลุ่มผู้ใช้: Job_Hunter (เตรียมฝึกงานสายข้อมูล)\\nภาษา: ไทย', 'history_summary_text': 'สรุปพฤติกรรม 30 วันล่าสุด (รวม 9 เหตุการณ์):\\nธีมที่มีการมีส่วนร่วมสูง:\\n- data_career: คะแนน=12.7, เหตุการณ์=9, ไลก์=1, คลิก=1, dwell สูงสุด=52000ms\\nฟีดล่าสุดที่มีปฏิสัมพันธ์ (ตัดสั้น):\\n- (1) TH_F001 | แนวทางทำพอร์ต Data Analyst ด้วยโปรเจกต์ Python และ SQL | แนวทางทำพอร์ต Data Analyst ด้วยโปรเจกต์ Python และ SQL\\n- (2) TH_F003 | เทคนิคเตรียมสัมภาษณ์ฝึกงาน Data Analyst (SQL + Python) | เทคนิคเตรียมสัมภาษณ์ฝึกงาน Data Analyst (SQL + Python)\\n- (3) TH_F009 | โปรเจกต์ Python วิเคราะห์ข้อมูลจริง: ตั้งแต่ทำความสะอาดถึงสรุป insight | โปรเจกต์ Python วิเคราะห์ข้อมูลจริง: ตั้งแต่ทำความสะอาดถึงสรุป insight\\n- (4) TH_F008 | รวมโจทย์ SQL ฝึกสัมภาษณ์ระดับฝึกงาน (พร้อมเฉลยแนวคิด) | รวมโจทย์ SQL ฝึกสัมภาษณ์ระดับฝึกงาน (พร้อมเฉลยแนวคิด)\\n- (5) TH_F017 | Portfolio Project: วิเคราะห์ยอดขาย + สร้าง KPI Dashboard | Portfolio Project: วิเคราะห์ยอดขาย + สร้าง KPI Dashboard', 'hyde_output': {'output_language': 'th', 'hyde_queries': [{'query_id': 'Q1', 'query_text': 'แนวทางสร้างพอร์ต Data Analyst ด้วยโปรเจกต์ Python SQL', 'weight': 1.0, 'intent_label': 'history_aligned'}, {'query_id': 'Q2', 'query_text': 'โจทย์ SQL Python สำหรับสัมภาษณ์ Data Analyst', 'weight': 1.0, 'intent_label': 'history_aligned'}, {'query_id': 'Q3', 'query_text': 'โปรเจกต์วิเคราะห์ข้อมูล Python SQL สร้างพอร์ตฝึกงาน', 'weight': 1.0, 'intent_label': 'practical'}, {'query_id': 'Q4', 'query_text': 'เทคนิคการนำเสนอข้อมูลและสร้าง Dashboard ที่น่าสนใจ', 'weight': 0.6, 'intent_label': 'exploratory'}, {'query_id': 'Q5', 'query_text': 'คำแนะนำการเตรียมตัวสัมภาษณ์พฤติกรรม Data Analyst', 'weight': 0.6, 'intent_label': 'exploratory'}]}, 'hyde_query_embeddings': {'path': 'stu_p001_hyde_q_emb.npy', 'model': 'gemini-embedding-001', 'dim': 768, 'dtype': 'float32', 'num_queries': 5, 'normalized': True}}\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Generate one cached bundle per student\n",
    "# ------------------------------------------------------------------\n",
    "for _, row in students.iterrows():\n",
    "    print(_)\n",
    "    student_row = row.to_dict()     # convert pd -> dict for each row\n",
    "    # print(student_row)\n",
    "    student_id  = str(student_row.get(\"student_id\",\"\")).strip()\n",
    "    if not student_id or student_id.lower() == \"nan\":\n",
    "        raise ValueError(f\"Invalid student_id in students.csv: {student_row!r}\")\n",
    "    \n",
    "    user_ctx = build_user_context(student_row)\n",
    "    # print(user_ctx)\n",
    "    pref_lang = user_ctx.user_context_json.get(\"preferred_language\",\"th\")\n",
    "\n",
    "    user_events = interactions[interactions[\"user_id\"] == student_id]   # <- user event from interaction.csv\n",
    "    # print(user_events)\n",
    "    num_events  = int(len(user_events))\n",
    "\n",
    "    history_summary_text : Optional[str] = None\n",
    "    #** Crate by combe data for each person student **#\n",
    "    if num_events > 0:\n",
    "        history_summary_text = build_history_summary(\n",
    "            user_events,\n",
    "            preferred_language   = pref_lang,\n",
    "            include_recent_feeds = include_recent_feeds,\n",
    "            recent_k             = recent_k,\n",
    "            feeds_lookup         = feeds_lookup or None,\n",
    "            feed_text_max_chars  = feed_text_max_chars,\n",
    "        )\n",
    "    \n",
    "    prompt_key = choose_hyde_prompt_key(num_events,history_threshold)\n",
    "    print(f\"promt_key -> {prompt_key}\")\n",
    "    template = prompts.get(prompt_key)\n",
    "    if not template:\n",
    "        raise ValueError(f\"Missing prompt '{prompt_key}' in pormpts.yaml\")\n",
    "    prompt = render_prompt(\n",
    "            template=template,\n",
    "            preferred_language=pref_lang,\n",
    "            user_context_text=user_ctx.user_context_text,\n",
    "            history_summary_text=history_summary_text,\n",
    "        )\n",
    "    # ------------------------------------------------------------------\n",
    "    # LLM call (JSON-only)\n",
    "    # ------------------------------------------------------------------\n",
    "    hyde_json = client.generate_json(prompt)\n",
    "    # ------------------------------------------------------------------\n",
    "    # Embed HyDE queries for fast serving\n",
    "    # ------------------------------------------------------------------\n",
    "    hyde_query_texts = _extract_hyde_query_texts(hyde_json)\n",
    "    print(f\"hyde_query_texts->{hyde_query_texts}\")\n",
    "\n",
    "    if hyde_query_texts:\n",
    "        emb = query_embedder.embed_documents(hyde_query_texts)\n",
    "        emb = np.asarray(emb, dtype = np.float32)\n",
    "        if emb.ndim != 2:\n",
    "            raise ValueError(f\"Invalid embedding shape {emb.shape}\")\n",
    "        emb = _l2_normalize_rows(emb)\n",
    "        print(f\"emb -> \\n{emb}\")\n",
    "        if expected_dim and emb.shape[1] != expected_dim:\n",
    "            raise ValueError(\n",
    "                f\"Embedding dim mismatch for student = {student_id}:\"\n",
    "                f\"got {emb.shape[1]} expected {expected_dim}\"\n",
    "            )\n",
    "        dim = int(emb.shape[1])\n",
    "    else:\n",
    "        dim = expected_dim or 0\n",
    "        emb = np.zeros((0,dim), dtype=np.float32)\n",
    "\n",
    "    emb_filename = f\"{student_id}_hyde_q_emb.npy\"\n",
    "    emb_path     = os.path.join(out_dir, emb_filename)\n",
    "    print(f\"emb_path ->\\n{emb_path}\")\n",
    "    _atomic_save_npy(emb_path, emb)\n",
    "    # ---------------------------------------------------\n",
    "    # Persist cached bundle for online serving\n",
    "    # ---------------------------------------------------\n",
    "    bundle: Dict[str, Any] = {\n",
    "        \"bundle_version\"        : \"v2_hyde_embedded_queries\",\n",
    "        \"student_id\"            : student_id,\n",
    "        \"generated_at\"          : now_iso,\n",
    "        \"prompt_key\"            : prompt_key,\n",
    "        \"preferred_language\"    : pref_lang,\n",
    "        \"num_events\"            : num_events,\n",
    "        \"user_context_json\"     : user_ctx.user_context_json,\n",
    "        \"user_context_text\"     : user_ctx.user_context_text,\n",
    "        \"history_summary_text\"  : history_summary_text,\n",
    "        \"hyde_output\"           : hyde_json,\n",
    "        \"hyde_query_embeddings\" : {\n",
    "            \"path\"        : emb_filename,\n",
    "            \"model\"       : query_embedding_model_name,\n",
    "            \"dim\"         : dim,\n",
    "            \"dtype\"       : \"float32\",\n",
    "            \"num_queries\" : int(len(hyde_query_texts)),\n",
    "            \"normalized\"  : True,\n",
    "        },\n",
    "    }\n",
    "    print(f\"bundle->\\n{bundle}\")\n",
    "\n",
    "    out_path = os.path.join(out_dir, f\"{student_id}.json\")\n",
    "    with open(out_path,\"w\",encoding=\"utf-8\") as f:\n",
    "        json.dump(bundle,f,ensure_ascii=False,indent=2)\n",
    "    logger.info(\n",
    "        \"wrote HyDE bundle student_id=%s events=%d prompt=%s\",\n",
    "        student_id,\n",
    "        num_events,\n",
    "        prompt_key,\n",
    "    )\n",
    "    print(\"#\"*100)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7bc2ed-0b97-457c-9b6a-3121e85a4ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "340fe8b9-62c7-4cf6-af0d-e163be759544",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a00ca0-4a23-454d-9be8-d9e6ead1fed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
